# -*- coding: utf-8 -*-
"""Homework: Machine Learning with Python

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Dms75UJwI-iNXnnaswHqczH2mdr3Ty5m
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

df = pd.read_csv('weatherAUS.csv')
df.head()

to_drop = ['Location', 'Date']
df.drop(to_drop, inplace=True, axis=1)

df['RainToday'] = df['RainToday'].fillna('No')
df['RainTomorrow'] = df['RainTomorrow'].fillna('No')
missing_values_numeric_features  = [col for col in df.columns if (df.isnull().sum()[col] > 0) & (df[col].dtypes != 'object')]
def impute_means(df, missing_values_columns):
    data = df.copy()
    '''Filling missing values with mean'''
    for col in missing_values_columns:
        data[col] = data[col].fillna(data[col].mean())
        
    return data
df = impute_means(df,missing_values_numeric_features)
df.isnull().sum()

print(df)

df.plot(x="Rainfall", y="Humidity9am", kind="scatter")

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix

df = pd.read_csv('weatherAUS.csv')
df.head()

to_drop = ['Location', 'Date']
df.drop(to_drop, inplace=True, axis=1)

df['RainToday'] = df['RainToday'].fillna('No')
df['RainTomorrow'] = df['RainTomorrow'].fillna('No')
missing_values_numeric_features  = [col for col in df.columns if (df.isnull().sum()[col] > 0) & (df[col].dtypes != 'object')]
def impute_means(df, missing_values_columns):
    data = df.copy()
    '''Filling missing values with mean'''
    for col in missing_values_columns:
        data[col] = data[col].fillna(data[col].mean())
        
    return data
df = impute_means(df,missing_values_numeric_features)
df.isnull().sum()

print(df)

df.plot(x="Rainfall", y="Humidity9am", kind="scatter") 
df.head()
df.info()


x = np.arange(10).reshape(-1, 1)
y = np.array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1])

df = LogisticRegression(solver= 'liblinear', random_state=0).fit(x,y)
df.fit(x, y)

df.classes_
df.intercept_
df.coef_
df.predict_proba(x)
df.predict(x)
df.score(x, y)
confusion_matrix(y, df.predict(x))

import pandas as pd
import numpy as np
import seaborn as sb
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn import tree
import pydotplus
from sklearn.tree import DecisionTreeRegressor
import matplotlib.pyplot as plt
import matplotlib.image as pltimg
import matplotlib.pyplot as plt
from sklearn.neighbors import KNeighborsRegressor

df = pd.read_csv('weatherAUS.csv')
print('\Data Frame \n', df)

# Data Exploration
df.head()

df.info()

df.describe()

df.shape

df.columns 


# Data Cleaning
df = df.drop(columns=['Location', 'Date', 'WindGustDir', 'WindDir9am', 'WindDir3pm'])
print(df)


# Graphs
df.plot(x="Humidity9am", y="Rainfall", kind="scatter") 
df.plot(x= "Humidity3pm", y="Rainfall", kind = "scatter")




# Linear Regression

print(df.head())
print('\n Data Frame Dimensions', df.shape)


X = df.iloc[:, 0:12]

y = df.iloc[:, 13]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)

print('train size:', X_train.shape)
print('test size:', X_test.shape)



# Decision Tree 
# we are going to try and create a decision tree 
d = {'WindGustDir': 1}

df['WindGustDir'] =  df['WindGustDir'].map(d)

d = {'YES': 1, 'NO': 0}
df['Go'] = df['Go'].map(d)

print(df)

features = ['Rainfall', 'Presure3pm', 'Pressure9am', 'WindDir3pm', 'WindDir9am', 'WindGustDir']

X = df[features]
y = df['Go']

print(X)
print(y)

dtree = DecisionTreeClassifier()
dtree = dtree.fit(X, y) 

data = tree.export_graphviz(dtree, out_file=None, feature_names=features)
graph = pydotplus.graph_from_dot_data(data)


# kNN 
regressor = KNeighborsRegressorn(n_Rainfall=3)
regressor.fit(X_train, y_train)

X_train_scaled = scaler.transform(X_train)
X_test = scaler.transform(X_test) 



#Analysis 
# Based on the results used for this project I have came to the conclusion that there is some data that needs more defining features to work properly. 
# Some data can be read and calculated properly but if not defined properly it will have a difficult time displaying any data. However when it comes to inputting data presented
# it is possiable to get whatever results needed. Python seems to run at a decent enough pase if not faster than R. With more data outputs than normal comparative to R though both can suffer 
# from a lack of uncorprative data, or hard to translate. They both should work with any given algorith put within either of the making less hasssel to work with the data.  



# My Thought's 
# this Language is just as frustrating to work in as R. Though there are some things that make it remotley comprhensiable to write code in this language is still as difficult.
# However if it is to be belevied that Python is better than R for machine learning then I can potentially see how that argument is sound. It definietly lessens the amount of data reading
# and conversions need to calculate data and display data. Even though most of my value did not end up working or there were error's that



"""# New Section"""